#!/bin/bash
#
# pi2s3
#
# Author: neutralvibes
# https://github.com/neutralvibes/pi2s3
#
set -o pipefail

VERSION=0.0.1
SCRIPT_NAME=`basename "$0"`
cd "$(dirname "$0")"
SCRIPT_PATH=`pwd -P`

showTitles() {
    echo $SCRIPT_NAME $VERSION - $1
}

if [[ ! -f config/backup.cfg ]]; then
    showTitles ERROR
    echo "
The configuration file is missing.

Do the following to set this utility up:

cp config/samples/* config/
cp scripts/samples/* scripts/
chmod +x pi2s3 scripts/*

---
"
    exit 1
fi

source config/backup.cfg

BACKUPS_ROOT_FOLDER=$BACKUP_BUCKET/$BACKUP_BUCKET_FOLDER

awsPathExists() {
    local m="S3 PathExists? $1"
    $S3_CMD info $1 > /dev/null 2>&1
    [[ $? -eq 0 ]] && return 0
    return 1
}

awsGetFile() { $S3_CMD get $1 $2; }
awsPutFile() { $S3_CMD put $1 $2; }

canIRun() {
    [ -f "$1" ] && [ -x "$1" ] && return 0
    return 1
}

awsPathExists ${BACKUP_BUCKET}

if [ $? -eq 1 ]; then
    echo "The S3 bucket, $BACKUP_BUCKET, does not exist."
    echo "Please make sure you have created the bucket OR, edit config/backup.cfg and enter the correct bucket name."
    exit 1
fi

usage() {
    showTitles usage
echo "
Creates tar backups to S3 storage

Usage:
    info        $SCRIPT_NAME info
    run         Run backup
    ls	        List backup weeks
    ls	[week]  List contents of week folder
"
    exit 0
}

showYesNo() { [ $1 -eq 0 ] && echo "no" || echo "yes"; }

showInfo() {
    showTitles info
    echo -e "
Bucket: $BACKUP_BUCKET
Bucket folder: $BACKUP_BUCKET_FOLDER
Backup extension: $BACKUP_FILE_EXT
Keep weeks: $KEEP_BACKUP_WEEKS
Include list: $INCLUDE_LIST
Exclude list: $EXCLUDE_LIST
After backup: $AFTER_BACKUP_SCRIPT
Before backup: $BEFORE_BACKUP_SCRIPT
Max backup logs: $MAX_BACKUP_LOGS
Check is root: $(showYesNo $CHECK_ROOT)
Save apt list: $(showYesNo $CREATE_APT_INSTALLED)
Temp path: $TMP_PATH
S3 command: $S3_CMD
"
    exit 0
}

[[ -z $1 ]] && usage

if [ $1 == 'ls' ]; then
    if [ -z $2 ]; then
        $S3_CMD ls $BACKUPS_ROOT_FOLDER/
    else
        $S3_CMD ls $BACKUPS_ROOT_FOLDER/$2/$3
    fi
    exit 0
elif [ $1 == 'info' ]; then
    showInfo
elif [ $1 != 'run' ]; then
    usage
fi

if [ $CHECK_ROOT -eq 1 ] && [ $(id -u) -ne 0 ]; then
    echo "-- BACKUP FAILED, configured to run as root, perhaps use 'sudo $SCRIPT_NAME', exiting..."
    exit 1
fi

mkdir -p $LOCAL_LOG_PATH

startPath=$PWD
startSecs=$SECONDS

DATE_SHORT=$(date +"%F_%H%M")
startDateTime=$(date +"%F_%H%M")
export LOG_FILE=$LOCAL_LOG_PATH/${startDateTime}_bck.log

#
# If LOGS_ENABLED not defined turn it off
#
if [ -z $LOGS_ENABLED ]; then
    export LOGS_ENABLED=0
fi

msg() {
    local dte=$(date +"%F %T")
    echo -e "[$dte] $@"
    if [ $LOGS_ENABLED -eq 1 ]; then
        echo -e "[$dte] $@" >>$LOG_FILE
    fi
}

elapsedTime() {
    local st=startSecs
    local ts=$((SECONDS - st))
    local seconds=$((ts % 60))
    local minutes=$((ts / 60 % 60))
    local hours=$((ts / 60 / 60 % 24))
    echo $hours hours, $minutes minutes, $seconds seconds
}


failed() {
    msg "BACKUP-FAILED for host, [$HOSTNAME]"
    exit 1
}

#
# If Monday create folder and set working folder
#
msg "\n\n*** STARTING BACKUP ***"
msg "Backup running under $USER account"

if [ $LOGS_ENABLED -eq 0 ]; then
    msg "Log file disabled"
else
    msg "Log file enabled"
fi

#
# Check LOCAL_LOG_PATH
#
if [ ! -d "$LOCAL_LOG_PATH" ]; then
    msg "FOLDER-NOT-PRESENT Creating folder, $LOCAL_LOG_PATH"
    mkdir -p $LOCAL_LOG_PATH
fi

#
# Check local TMP_PATH
#
if [ ! -d "$TMP_PATH" ]; then
    msg "FOLDER-NOT-PRESENT Creating folder, $TMP_PATH"
    mkdir -p $TMP_PATH
else
    msg "Cleaning folder, $TMP_PATH"
    rm $TMP_PATH/*.* > /dev/null 2>&1
fi

#
# Set backups destination folder
# ===============================
#
# If it's a Monday, select new week folder
#
if [ $(date +"%w") -eq 1 ]; then
    BACKUP_FOLDER=${BACKUPS_ROOT_FOLDER}/$(date +"%F")
else
    # Not Monday, use last Monday's date folder.
    BACKUP_FOLDER=${BACKUPS_ROOT_FOLDER}/$(date -dlast-monday +"%F")
fi

#
# Snapshot file.
#
snarName=backup.snar
snar=$BACKUP_FOLDER/$snarName

#
# Snapshot file to use for backup.
#
useSnar="$TMP_PATH/$snarName"

#
# If the snapshot is present a full backup is already in folder.
#
fn=${DATE_SHORT} #Filename

#
# Backup mode (works out mode internally)
#   0 = full / 1 = incremental
#
backupMode=0

if [ ! -f "$INCLUDE_LIST" ]; then
    msg "NO-INCLUDE_LIST, $INCLUDE_LIST"
    msg "Cannot proceed."
    failed
else 
    msg "Include list: $INCLUDE_LIST"
fi

if [ ! -f "$EXCLUDE_LIST" ]; then
    msg "NO-EXCLUDE_LIST, $EXCLUDE_LIST"
    EXCLUSIONS_PARAM=""
else 
    EXCLUSIONS_PARAM="--exclude-from=$EXCLUDE_LIST"
fi



msg "You have 10 seconds to abort (ctrl-c) or backup will start.\n"
sleep 10

if canIRun "$BEFORE_BACKUP_SCRIPT"; then
    msg "Executing BEFORE backup tasks"
    $BEFORE_BACKUP_SCRIPT
else
    msg "Either no BEFORE backup tasks or not executable."
fi

awsPathExists "${snar}-1"

if [ $? -eq 0 ]; then
    msg "Incremental file IS present, will create a snapshot."
    fn+=_backup_snapshot
    backupMode=1
    # get backup snar to do level 1 from

    msg "Copying incremental file locally to use."
    awsGetFile $snar $TMP_PATH/${snarName}-1

    # We want to use the copy of the original snar file.
    useSnar="${TMP_PATH}/${snarName}-1"
else
    msg "Incremental file NOT present, will do full backup."
    fn+=_backup_full

fi

pathToFile="$BACKUP_FOLDER/${fn}.$BACKUP_FILE_EXT"

# Full path to report
pathToLog="$TMP_PATH/$fn.$BACKUP_FILE_EXT.log"

# Full path to log
pathToReport="$TMP_PATH/$fn.$BACKUP_FILE_EXT.lst"

# Fullpath to error log
pathToErrors="$TMP_PATH/$fn.$BACKUP_FILE_EXT.error.log"

msg "Running backup....."
msg "Using snapshot $useSnar"

#
# Make a list of installed packages
#
if [ ! -z $CREATE_APT_INSTALLED ] && [ $CREATE_APT_INSTALLED -eq 1 ]; then
    msg "Saving list of APT packages installed."
    sudo apt list --installed > $TMP_PATH/$fn.apt_installed.lst
else
    msg "Create APT installed list, disabled."
fi

sudo /bin/tar -czpSva \
    --exclude="$TMP_PATH" \
    $EXCLUSIONS_PARAM \
    --files-from=$INCLUDE_LIST \
    --totals \
    --index-file="$pathToReport" \
    --listed-incremental=$useSnar 2> $TMP_PATH/$fn.warnings.log |
    awsPutFile - $pathToFile

statusCode=$?

msg "Backup status code: $statusCode"

if [ $statusCode -ne 2 ]; then
    msg "\nCopying backup information files."
    awsPutFile "$TMP_PATH/*.*" "$BACKUP_FOLDER/"

    #
    # If it was a full backup make a copy for incrementals to detect
    #
    if [ $backupMode -eq 0 ]; then
        awsPutFile "$useSnar" "$BACKUP_FOLDER/${snarName}-1"
    fi
fi

if canIRun "$AFTER_BACKUP_SCRIPT"; then
    msg "Executing AFTER backup tasks"
    $AFTER_BACKUP_SCRIPT $statusCode
else
    msg "Either no AFTER backup tasks or not executable."
fi

[ $statusCode -eq 2 ] && failed

#
# clean up excess log files
#
numToRemove=$((MAX_BACKUP_LOGS + 1))
storePath=$PWD
cd $LOCAL_LOG_PATH
ls -tp | grep -v '/$' | tail -n +${numToRemove} | xargs -d '\n' -r rm -v --
cd $storePath

#
# Remove old  weeks if enabled
#
if [ ! -z $KEEP_BACKUP_WEEKS ]; then
    msg "KEEP_BACKUP_WEEKS = $KEEP_BACKUP_WEEKS, removing any excess"

    prn=$(
        $S3_CMD ls ${BACKUPS_ROOT_FOLDER}/ |
            grep DIR |
            sort -r |
            awk -v maxWeeks=$KEEP_BACKUP_WEEKS -v ORS="\n" 'NR > maxWeeks {print $2 }'
    )

    if [[ ! -z "$prn" ]]; then
        msg "Removing \n$prn"
        echo -e $prn | xargs -rI {} $S3_CMD rm -r {}
    else
        msg "No excess to reomove"
    fi
fi

msg "*** Backup finished in $(elapsedTime) ***"

#
# Upload log file
#
if [ $LOGS_ENABLED -eq 1 ]; then
    awsPutFile "$LOG_FILE" "$BACKUP_FOLDER/"
fi
